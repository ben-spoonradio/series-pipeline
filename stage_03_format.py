#!/usr/bin/env python3
"""
Stage 3: TTS Formatting
Format translated text for optimal TTS synthesis per target language
"""

import sys
import json
import time
import re
from pathlib import Path
from typing import List, Optional
from tqdm import tqdm
from processors.llm_processor import LLMProcessor
from processors.episode_utils import arabic_to_chinese

# Target languages
TARGET_LANGUAGES = ['korean', 'japanese', 'taiwanese']

# Language display names
LANGUAGE_DISPLAY = {
    'korean': 'ğŸ‡°ğŸ‡· Korean',
    'japanese': 'ğŸ‡¯ğŸ‡µ Japanese',
    'taiwanese': 'ğŸ‡¹ğŸ‡¼ Taiwanese'
}

# Korean number words
KOREAN_NUMBER_WORDS = {
    1: 'ì¼', 2: 'ì´', 3: 'ì‚¼', 4: 'ì‚¬', 5: 'ì˜¤',
    6: 'ìœ¡', 7: 'ì¹ ', 8: 'íŒ”', 9: 'êµ¬', 10: 'ì‹­'
}


def arabic_to_korean(num: int) -> str:
    """
    Convert Arabic number to Korean number word.

    Examples:
        1 â†’ ì¼, 10 â†’ ì‹­, 11 â†’ ì‹­ì¼, 21 â†’ ì´ì‹­ì¼, 50 â†’ ì˜¤ì‹­
    """
    if num <= 0:
        return str(num)

    if num <= 10:
        return KOREAN_NUMBER_WORDS[num]

    if num < 20:
        # 11-19: ì‹­ì¼, ì‹­ì´, ...
        ones = num % 10
        return f"ì‹­{KOREAN_NUMBER_WORDS[ones]}" if ones > 0 else "ì‹­"

    if num < 100:
        # 20-99
        tens = num // 10
        ones = num % 10
        result = f"{KOREAN_NUMBER_WORDS[tens]}ì‹­"
        if ones > 0:
            result += KOREAN_NUMBER_WORDS[ones]
        return result

    # For numbers >= 100, just return Arabic
    return str(num)

# Episode title patterns by language
EPISODE_PATTERNS = {
    'korean': [
        (r'^(\d+)í™”\s*[-:]\s*(.+?)(?:\n|$)', 1, 2),
        (r'^ì œ(\d+)í™”\s*[-:]\s*(.+?)(?:\n|$)', 1, 2),
    ],
    'japanese': [
        (r'^ç¬¬(\d+)è©±\s*[-:ï¼š]\s*(.+?)(?:\n|$)', 1, 2),
        (r'^(\d+)è©±\s*[-:ï¼š]\s*(.+?)(?:\n|$)', 1, 2),
    ],
    'taiwanese': [
        (r'^ç¬¬(\d+)è©±\s*[-:ï¼š]\s*(.+?)(?:\n|$)', 1, 2),
        (r'^ç¬¬(\d+)é›†\s*[-:ï¼š]\s*(.+?)(?:\n|$)', 1, 2),
    ]
}


def extract_title_from_content(content: str, language: str) -> tuple:
    """
    Extract episode title from content based on language.

    Returns:
        Tuple of (title, episode_number) or (None, None)
    """
    patterns = EPISODE_PATTERNS.get(language, EPISODE_PATTERNS['korean'])
    search_text = content[:500]

    for pattern, num_group, title_group in patterns:
        match = re.search(pattern, search_text, re.MULTILINE | re.IGNORECASE)
        if match:
            episode_num = int(match.group(num_group))
            title = match.group(title_group).strip()
            title = title.rstrip('.,;:')
            if title:
                return title, episode_num

    return None, None


def format_episode_header(episode_number: int, title: str, language: str) -> str:
    """
    Create TTS-friendly episode header based on language.

    Format:
        korean:    "Episode ì¼. ì œëª©."
        japanese:  "ç¬¬1è©±ã€‚ì œëª©ã€‚"
        taiwanese: "ç¬¬ä¸€é›†ã€‚ì œëª©ã€‚"
    """
    if language == 'korean':
        korean_num = arabic_to_korean(episode_number)
        return f"Episode {korean_num}. {title}.\n\n"
    elif language == 'japanese':
        return f"ç¬¬{episode_number}è©±ã€‚{title}ã€‚\n\n"
    elif language == 'taiwanese':
        chinese_num = arabic_to_chinese(episode_number)
        return f"ç¬¬{chinese_num}é›†ã€‚{title}ã€‚\n\n"
    else:
        return f"Episode {episode_number}. {title}.\n\n"


def clean_header_for_tts(content: str, episode_number: int, title: str, language: str) -> str:
    """
    Clean up episode header in content for TTS-friendly format.
    Removes ALL existing episode headers and adds a single standardized header.

    Example:
        Input:  "4í™”. ì œëª©.\n\nì—í”¼ì†Œë“œ ì‚¬í™”.\n\në³¸ë¬¸..."
        Output: "Episode ì‚¬. ì œëª©.\n\në³¸ë¬¸..."
    """
    cleaned = content

    # Korean number words
    korean_numbers = r'(?:ì¼|ì´|ì‚¼|ì‚¬|ì˜¤|ìœ¡|ì¹ |íŒ”|êµ¬|ì‹­|ë°±|ì²œ|' + \
                     r'í•˜ë‚˜|ë‘˜|ì…‹|ë„·|ë‹¤ì„¯|ì—¬ì„¯|ì¼ê³±|ì—¬ëŸ|ì•„í™‰|ì—´|' + \
                     r'[ì¼ì´ì‚¼ì‚¬ì˜¤ìœ¡ì¹ íŒ”êµ¬ì‹­ë°±ì²œ]+)'

    # Japanese hiragana numbers (for LLM-converted headers like ã ã„ã„ã£ã—ã‚…ã†, ã ã„ã‚ˆã‚“ã—ã‚…ã†)
    # Includes all readings: ã„ã¡(1), ã«(2), ã•ã‚“(3), ã—/ã‚ˆã‚“(4), ã”(5), ã‚ã(6), ã—ã¡/ãªãª(7), ã¯ã¡(8), ãã‚…ã†/ã(9), ã˜ã‚…ã†(10)
    hiragana_numbers = r'(?:ã„ã¡|ã«|ã•ã‚“|ã—|ã‚ˆã‚“|ã”|ã‚ã|ã—ã¡|ãªãª|ã¯ã¡|ãã‚…ã†|ã|ã˜ã‚…ã†|' + \
                       r'ã²ã‚ƒã|ã›ã‚“|ã„ã£|ã«ã£|ã•ã£|ã‚ˆã£|ã”ã£|ã‚ã£|ã—ã£|ã¯ã£|ãã‚…ã£|' + \
                       r'[ã„ã¡ã«ã•ã‚“ã—ã‚ˆã‚“ã”ã‚ãã—ã¡ãªãªã¯ã¡ãã‚…ã†ãã˜ã‚…ã†ã²ã‚ƒãã›ã‚“]+)'

    # Japanese number words
    japanese_numbers = r'(?:ä¸€|äºŒ|ä¸‰|å››|äº”|å…­|ä¸ƒ|å…«|ä¹|å|ç™¾|åƒ|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ]+)'

    # Remove ALL episode header patterns (may appear multiple times due to LLM formatting)
    # Apply repeatedly until no more matches

    patterns_to_remove = [
        # "Episode ì¼." or "Episode 1." with optional title
        r'^Episode\s+(?:\d+|' + korean_numbers + r')\s*[.ã€‚]?\s*(?:[^\n]+[.ã€‚])?\s*\n+',
        # "ì—í”¼ì†Œë“œ ì¼." or "ì—í”¼ì†Œë“œ 1." with optional title
        r'^ì—í”¼ì†Œë“œ\s*(?:\d+|' + korean_numbers + r')(?:í™”)?\s*[.ã€‚]?\s*(?:[^\n]+[.ã€‚])?\s*\n+',
        # "1í™”." or "ì œ1í™”." with optional title
        r'^(?:ì œ)?(?:\d+)í™”\s*[.ã€‚:]\s*(?:[^\n]+[.ã€‚])?\s*\n+',
        # "ç¬¬1è©±" or "ç¬¬ä¸€è©±" with optional title (kanji)
        r'^ç¬¬(?:\d+|' + japanese_numbers + r')è©±\s*[.ã€‚]?\s*(?:[^\n]+[.ã€‚ã€‚])?\s*\n+',
        # "ç¬¬1é›†" with optional title (kanji)
        r'^ç¬¬(?:\d+|' + japanese_numbers + r')é›†\s*[.ã€‚]?\s*(?:[^\n]+[.ã€‚ã€‚])?\s*\n+',
        # Hiragana episode headers (LLM-converted): "ã ã„ã„ã£ã—ã‚…ã†ã€‚" "ã ã„ã«ã—ã‚…ã†ã€‚" etc.
        r'^ã ã„' + hiragana_numbers + r'(?:ã—ã‚…ã†|ã‚|ã‹)\s*[.ã€‚]?\s*\n+',
        # Generic hiragana chapter patterns
        r'^(?:ã ã„)?(?:' + hiragana_numbers + r')(?:ã—ã‚…ã†|ã‚|ã‹|ã°ã‚“)\s*[.ã€‚]?\s*\n+',
    ]

    # Apply each pattern removal repeatedly
    for pattern in patterns_to_remove:
        prev_cleaned = None
        while prev_cleaned != cleaned:
            prev_cleaned = cleaned
            cleaned = re.sub(pattern, '', cleaned, count=1, flags=re.IGNORECASE | re.MULTILINE)

    # Remove leading whitespace
    cleaned = cleaned.lstrip('\n\r\t ')

    # Add standardized header based on language
    tts_header = format_episode_header(episode_number, title, language)
    cleaned = tts_header + cleaned

    return cleaned


def run_stage_3(
    series_folder: Path,
    target_languages: Optional[List[str]] = None,
    max_episodes: int = None
):
    """
    Run Stage 3: TTS Formatting for each target language

    Args:
        series_folder: Path to series folder
        target_languages: List of target languages (default: all 3)
        max_episodes: Maximum number of episodes to process (None = all)
    """
    if target_languages is None:
        target_languages = TARGET_LANGUAGES

    print("=" * 80)
    print("STAGE 3: TTS Formatting")
    print("=" * 80)
    print()

    stage_02_translated = series_folder / '02_translated'
    stage_03_formatted = series_folder / '03_formatted'

    if not stage_02_translated.exists():
        print(f"âŒ Stage 2 output not found: {stage_02_translated}")
        print("   Please run stage_02_translate.py first")
        return False

    print(f"ğŸ“ Series: {series_folder.name}")
    print(f"ğŸŒ Languages to format: {', '.join(target_languages)}")
    print()
    print("-" * 80)
    print()

    llm_processor = LLMProcessor()
    overall_success = True

    for target_lang in target_languages:
        print(f"\n{'='*60}")
        print(f"  Formatting {LANGUAGE_DISPLAY.get(target_lang, target_lang)}")
        print(f"{'='*60}\n")

        source_folder = stage_02_translated / target_lang
        target_folder = stage_03_formatted / target_lang

        if not source_folder.exists():
            print(f"  âš ï¸  Source folder not found: {source_folder}")
            print(f"     Skipping {target_lang}...")
            continue

        target_folder.mkdir(parents=True, exist_ok=True)

        # Get all episode files
        episodes = sorted(source_folder.glob('episode_*.json'))

        if not episodes:
            print(f"  âš ï¸  No episode files found in {source_folder}")
            continue

        # Apply max_episodes limit if specified
        total_episodes = len(episodes)
        if max_episodes and len(episodes) > max_episodes:
            print(f"  ğŸ“‹ Limiting to first {max_episodes} episodes (total: {total_episodes})")
            episodes = episodes[:max_episodes]

        print(f"  ğŸ“Š Episodes to format: {len(episodes)}")

        # Track progress
        failed_episodes = []
        skipped_episodes = []
        processed_count = 0

        with tqdm(total=len(episodes), desc="  Formatting", bar_format='{desc}: {n}/{total}|{bar}| [{elapsed}<{remaining}]') as pbar:
            for episode_file in episodes:
                output_file = target_folder / episode_file.name

                # Skip if already processed
                if output_file.exists():
                    try:
                        with open(output_file, 'r', encoding='utf-8') as f:
                            existing_data = json.load(f)
                            if existing_data.get('metadata', {}).get('formatting_applied'):
                                pbar.write(f"     â­ï¸  Skipped {episode_file.name}")
                                skipped_episodes.append(episode_file.name)
                                pbar.update(1)
                                continue
                    except Exception:
                        pass

                try:
                    # Load episode
                    with open(episode_file, 'r', encoding='utf-8') as f:
                        episode_data = json.load(f)

                    content = episode_data['content']
                    series_name = episode_data.get('metadata', {}).get('series_name', series_folder.name)
                    episode_number = episode_data.get('episode_number', 1)
                    current_title = episode_data.get('title')

                    # Format for TTS with retry logic
                    max_retries = 3
                    retry_delay = 10
                    formatted_text = None

                    for attempt in range(max_retries):
                        try:
                            format_result = llm_processor.execute({
                                'text': content,
                                'operation': 'format',
                                'params': {'language': target_lang}
                            })
                            formatted_text = format_result['output']
                            break
                        except Exception as e:
                            if attempt < max_retries - 1:
                                pbar.write(f"     âš ï¸  Retry {attempt + 1}/{max_retries}: {e}")
                                time.sleep(retry_delay)
                            else:
                                raise

                    if formatted_text is None:
                        raise Exception("Formatting failed after retries")

                    # Handle title
                    final_title = None
                    title_source = None

                    if current_title:
                        final_title = current_title
                        title_source = 'existing'
                    else:
                        # Try to extract title
                        extracted_title, _ = extract_title_from_content(content, target_lang)
                        if extracted_title:
                            final_title = extracted_title
                            title_source = 'extracted'
                        else:
                            # Generate title using LLM
                            for attempt in range(max_retries):
                                try:
                                    title_result = llm_processor.execute({
                                        'text': formatted_text,
                                        'operation': 'generate_title',
                                        'params': {
                                            'series_name': series_name,
                                            'episode_number': episode_number,
                                            'language': target_lang
                                        }
                                    })
                                    final_title = title_result['output']
                                    title_source = 'generated'
                                    break
                                except Exception:
                                    if attempt == max_retries - 1:
                                        # Default title by language
                                        if target_lang == 'korean':
                                            final_title = f"ì—í”¼ì†Œë“œ {episode_number}"
                                        elif target_lang == 'japanese':
                                            final_title = f"ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode_number}"
                                        elif target_lang == 'taiwanese':
                                            final_title = f"ç¬¬{episode_number}é›†"
                                        else:
                                            final_title = f"Episode {episode_number}"
                                        title_source = 'default'

                    # Clean header for TTS-friendly format
                    if final_title:
                        formatted_text = clean_header_for_tts(
                            formatted_text, episode_number, final_title, target_lang
                        )

                    # Save formatted episode
                    episode_data['content'] = formatted_text
                    episode_data['title'] = final_title
                    episode_data['metadata']['formatting_applied'] = True
                    episode_data['metadata']['formatting_language'] = target_lang
                    episode_data['metadata']['title'] = final_title
                    episode_data['metadata']['title_source'] = title_source

                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(episode_data, f, ensure_ascii=False, indent=2)

                    processed_count += 1
                    pbar.set_postfix_str(f"{episode_file.name}")
                    pbar.update(1)

                except Exception as e:
                    pbar.write(f"     âŒ Failed {episode_file.name}: {e}")
                    failed_episodes.append((episode_file.name, str(e)))
                    pbar.update(1)

        # Summary for this language
        print()
        print(f"  {LANGUAGE_DISPLAY.get(target_lang, target_lang)} Summary:")
        print(f"    Processed: {processed_count}")
        print(f"    Skipped: {len(skipped_episodes)}")
        print(f"    Failed: {len(failed_episodes)}")

        if failed_episodes:
            overall_success = False

    print()
    print("=" * 80)
    print("Stage 3 Complete")
    print("=" * 80)
    print()

    if overall_success:
        print("âœ… All formatting completed successfully!")
        print()
        print("ğŸ“‹ Next Steps:")
        print("   1. Review formatted files in: " + str(stage_03_formatted))
        print("   2. Run: python stage_04_tag_emotions.py")
    else:
        print("âš ï¸  Some formatting failed. Review and retry.")

    return overall_success


if __name__ == '__main__':
    import argparse
    from dotenv import load_dotenv
    load_dotenv()

    parser = argparse.ArgumentParser(
        description='Stage 3: TTS Formatting',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python stage_03_format.py "processed/Publisher/Series"
  python stage_03_format.py "processed/Publisher/Series" --langs korean japanese

This stage:
  1. Reads translated episodes from 02_translated/{language}/
  2. Applies language-specific TTS formatting
  3. Generates episode titles if missing
  4. Outputs to 03_formatted/{language}/
        """
    )
    parser.add_argument('series_folder', help='Path to series folder')
    parser.add_argument(
        '--langs',
        nargs='+',
        choices=['korean', 'japanese', 'taiwanese'],
        default=TARGET_LANGUAGES,
        help='Target languages (default: all three)'
    )
    parser.add_argument(
        '--max-episodes',
        type=int,
        default=None,
        help='Maximum number of episodes to process'
    )

    args = parser.parse_args()
    series_folder = Path(args.series_folder)

    if not series_folder.exists():
        print(f"âŒ Series folder not found: {series_folder}")
        sys.exit(1)

    success = run_stage_3(series_folder, target_languages=args.langs, max_episodes=args.max_episodes)
    sys.exit(0 if success else 1)
